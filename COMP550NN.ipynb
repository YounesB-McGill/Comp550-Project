{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\anmoljeet\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, LSTM, Bidirectional, Embedding, Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentences = 'lol'\n",
    "#to merge csv files, use\n",
    "#copy *.csv merged.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   Sentence         Intent\n",
      "0  add the binary attribute state to lumber  add_attribute\n",
      "1    add an boolean attribute number to pie  add_attribute\n",
      "2      add a numeric attribute value to dog  add_attribute\n",
      "3      add a boolean attribute id to belief  add_attribute\n",
      "4  ghost contains a numeric attribute count  add_attribute\n"
     ]
    }
   ],
   "source": [
    "dataSet = pd.read_csv('merged.csv', encoding = \"latin1\", names = [\"Sentence\", \"Intent\"])\n",
    "print(dataSet.head())\n",
    "intent = dataSet[\"Intent\"]\n",
    "keyIntent = list(set(intent))\n",
    "sentences = list(dataSet[\"Sentence\"])\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(sentences):\n",
    "    wordList = []\n",
    "    for i in sentences:\n",
    "        subbedSentence = re.sub(r'[^ a-z A-Z 0-9]', \" \", i)\n",
    "        words = word_tokenize(subbedSentence)\n",
    "        wordList.append([j.lower() for j in words]) \n",
    "    return wordList\n",
    "\n",
    "cleanedSetences = clean(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens(words, filters = '!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~'):\n",
    "    token = Tokenizer(filters = filters)\n",
    "    token.fit_on_texts(words)\n",
    "    return token\n",
    "\n",
    "wordTokens = tokens(cleanedSetences)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size = 365 and Maximum length = 8\n"
     ]
    }
   ],
   "source": [
    "def maxLength(words):\n",
    "    return(len(max(words, key = len)))\n",
    "\n",
    "vocabSize = len(wordTokens.word_index) + 1\n",
    "maxLengthz = maxLength(cleanedSetences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(tokens, words):\n",
    "    return(tokens.texts_to_sequences(words))\n",
    "\n",
    "encodedSentences = encoder(wordTokens, cleanedSetences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padder(words, maxLen):\n",
    "    return(pad_sequences(words, maxlen = maxLengthz, padding = \"post\"))\n",
    "\n",
    "paddedSentences = padder(encodedSentences, maxLengthz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHotEncoder(encode):\n",
    "    oneHot = OneHotEncoder(sparse = False)\n",
    "    return(oneHot.fit_transform(encode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "intentTokens = tokens(keyIntent, filters = '!\"#$%&()*+,-/:;<=>?@[\\]^`{|}~')\n",
    "tokenOutput = encoder(intentTokens, intent)\n",
    "tokenOutput = np.array(tokenOutput).reshape(len(tokenOutput), 1)\n",
    "oneHotOutput = oneHotEncoder(tokenOutput)\n",
    "\n",
    "xTrain, xValid, yTrain, yValid = train_test_split(paddedSentences, oneHotOutput, shuffle = True, test_size = 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_model(vocabSizez, maxLen, input_shape):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocabSizez, 128))\n",
    "    model.add(Bidirectional(LSTM(128)))\n",
    "    #model.add(Dense(128, activation = \"relu\"))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation = \"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(32, activation = \"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(5, activation = \"softmax\"))\n",
    "  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2121, 8)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_21 (Embedding)     (None, None, 128)         46720     \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 256)               263168    \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 328,581\n",
      "Trainable params: 328,581\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2121 samples, validate on 375 samples\n",
      "Epoch 1/150\n",
      "2121/2121 [==============================] - 6s 3ms/step - loss: 1.2152 - acc: 0.4781 - val_loss: 0.3357 - val_acc: 0.9813\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.33572, saving model to modelLSTM.h5\n",
      "Epoch 2/150\n",
      "2121/2121 [==============================] - 2s 774us/step - loss: 0.2965 - acc: 0.8878 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.33572 to 0.00293, saving model to modelLSTM.h5\n",
      "Epoch 3/150\n",
      "2121/2121 [==============================] - 1s 575us/step - loss: 0.1024 - acc: 0.9642 - val_loss: 1.8908e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00293 to 0.00019, saving model to modelLSTM.h5\n",
      "Epoch 4/150\n",
      "2121/2121 [==============================] - 1s 582us/step - loss: 0.0659 - acc: 0.9755 - val_loss: 3.6352e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00019 to 0.00004, saving model to modelLSTM.h5\n",
      "Epoch 5/150\n",
      "2121/2121 [==============================] - 1s 575us/step - loss: 0.0607 - acc: 0.9811 - val_loss: 4.9904e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00004 to 0.00000, saving model to modelLSTM.h5\n",
      "Epoch 6/150\n",
      "2121/2121 [==============================] - 1s 575us/step - loss: 0.0455 - acc: 0.9830 - val_loss: 0.2932 - val_acc: 0.9680\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00000\n",
      "Epoch 7/150\n",
      "2121/2121 [==============================] - 1s 560us/step - loss: 0.0614 - acc: 0.9821 - val_loss: 1.2144e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00000 to 0.00000, saving model to modelLSTM.h5\n",
      "Epoch 8/150\n",
      "2121/2121 [==============================] - 1s 545us/step - loss: 0.0399 - acc: 0.9887 - val_loss: 0.0436 - val_acc: 0.9947\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00000\n",
      "Epoch 9/150\n",
      "2121/2121 [==============================] - 1s 553us/step - loss: 0.0465 - acc: 0.9920 - val_loss: 8.2430e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00000 to 0.00000, saving model to modelLSTM.h5\n",
      "Epoch 10/150\n",
      "2121/2121 [==============================] - 1s 560us/step - loss: 0.0279 - acc: 0.9915 - val_loss: 1.6753e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00000 to 0.00000, saving model to modelLSTM.h5\n",
      "Epoch 11/150\n",
      "2121/2121 [==============================] - 1s 553us/step - loss: 0.0339 - acc: 0.9910 - val_loss: 5.9701e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00000\n",
      "Epoch 12/150\n",
      "2121/2121 [==============================] - 2s 1ms/step - loss: 0.0234 - acc: 0.9906 - val_loss: 1.5799e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00000 to 0.00000, saving model to modelLSTM.h5\n",
      "Epoch 13/150\n",
      "2121/2121 [==============================] - 1s 597us/step - loss: 0.0203 - acc: 0.9934 - val_loss: 1.2207e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00000 to 0.00000, saving model to modelLSTM.h5\n",
      "Epoch 14/150\n",
      "2121/2121 [==============================] - 2s 803us/step - loss: 0.0298 - acc: 0.9920 - val_loss: 5.0758e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00000\n",
      "Epoch 15/150\n",
      "2121/2121 [==============================] - 1s 560us/step - loss: 0.0316 - acc: 0.9920 - val_loss: 0.0594 - val_acc: 0.9947\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.00000\n",
      "Epoch 16/150\n",
      "2121/2121 [==============================] - 1s 560us/step - loss: 0.0346 - acc: 0.9939 - val_loss: 9.2733e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.00000\n",
      "Epoch 17/150\n",
      "2121/2121 [==============================] - 1s 692us/step - loss: 0.0229 - acc: 0.9943 - val_loss: 1.5306e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.00000\n",
      "Epoch 18/150\n",
      "2121/2121 [==============================] - 1s 656us/step - loss: 0.0167 - acc: 0.9934 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.00000 to 0.00000, saving model to modelLSTM.h5\n",
      "Epoch 19/150\n",
      "2121/2121 [==============================] - 2s 729us/step - loss: 0.0153 - acc: 0.9934 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.00000\n",
      "Epoch 20/150\n",
      "2121/2121 [==============================] - 1s 611us/step - loss: 0.0133 - acc: 0.9948 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.00000\n",
      "Epoch 21/150\n",
      "2121/2121 [==============================] - 1s 626us/step - loss: 0.0178 - acc: 0.9925 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.00000\n",
      "Epoch 22/150\n",
      "2121/2121 [==============================] - 1s 641us/step - loss: 0.0121 - acc: 0.9948 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.00000\n",
      "Epoch 23/150\n",
      "2121/2121 [==============================] - 2s 810us/step - loss: 0.0088 - acc: 0.9962 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.00000\n",
      "Epoch 24/150\n",
      "2121/2121 [==============================] - 1s 656us/step - loss: 0.0117 - acc: 0.9958 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.00000\n",
      "Epoch 25/150\n",
      "2121/2121 [==============================] - 2s 847us/step - loss: 0.0182 - acc: 0.9920 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.00000\n",
      "Epoch 26/150\n",
      "2121/2121 [==============================] - 1s 538us/step - loss: 0.0096 - acc: 0.9962 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.00000\n",
      "Epoch 27/150\n",
      "2121/2121 [==============================] - 1s 582us/step - loss: 0.0115 - acc: 0.9958 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.00000\n",
      "Epoch 28/150\n",
      "2121/2121 [==============================] - 1s 611us/step - loss: 0.0139 - acc: 0.9953 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.00000\n",
      "Epoch 29/150\n",
      "2121/2121 [==============================] - 1s 626us/step - loss: 0.0151 - acc: 0.9934 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.00000\n",
      "Epoch 30/150\n",
      "2121/2121 [==============================] - 1s 494us/step - loss: 0.0100 - acc: 0.9958 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.00000\n",
      "Epoch 31/150\n",
      "2121/2121 [==============================] - 2s 818us/step - loss: 0.0144 - acc: 0.9929 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.00000\n",
      "Epoch 32/150\n",
      "2121/2121 [==============================] - 2s 987us/step - loss: 0.0128 - acc: 0.9925 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.00000\n",
      "Epoch 33/150\n",
      "2121/2121 [==============================] - 1s 656us/step - loss: 0.0137 - acc: 0.9939 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.00000\n",
      "Epoch 34/150\n",
      "2121/2121 [==============================] - 1s 626us/step - loss: 0.0138 - acc: 0.9948 - val_loss: 1.1921e-07 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00034: val_loss did not improve from 0.00000\n",
      "Epoch 35/150\n",
      "2121/2121 [==============================] - 1s 538us/step - loss: 0.0108 - acc: 0.9953 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.00000\n",
      "Epoch 36/150\n",
      "2121/2121 [==============================] - 3s 1ms/step - loss: 0.0147 - acc: 0.9948 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.00000\n",
      "Epoch 37/150\n",
      "2121/2121 [==============================] - 2s 840us/step - loss: 0.0088 - acc: 0.9958 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.00000\n",
      "Epoch 38/150\n",
      "2121/2121 [==============================] - 2s 722us/step - loss: 0.0059 - acc: 0.9967 - val_loss: 1.1921e-07 - val_acc: 1.0000 0s - loss: 0.\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.00000\n",
      "Epoch 39/150\n",
      "2121/2121 [==============================] - 2s 774us/step - loss: 0.0088 - acc: 0.9962 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.00000\n",
      "Epoch 40/150\n",
      "2121/2121 [==============================] - 1s 538us/step - loss: 0.0073 - acc: 0.9976 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.00000\n",
      "Epoch 41/150\n",
      "2121/2121 [==============================] - 1s 545us/step - loss: 0.0130 - acc: 0.9953 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.00000\n",
      "Epoch 42/150\n",
      "2121/2121 [==============================] - 1s 560us/step - loss: 0.0053 - acc: 0.9981 - val_loss: 1.1921e-07 - val_acc: 1.0000A: 0s - loss: 0.0070 \n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.00000\n",
      "Epoch 43/150\n",
      "2121/2121 [==============================] - 1s 545us/step - loss: 0.0100 - acc: 0.9958 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.00000\n",
      "Epoch 44/150\n",
      "2121/2121 [==============================] - 2s 774us/step - loss: 0.0078 - acc: 0.9958 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.00000\n",
      "Epoch 45/150\n",
      "2121/2121 [==============================] - 1s 648us/step - loss: 0.0041 - acc: 0.9981 - val_loss: 2.3397e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.00000\n",
      "Epoch 46/150\n",
      "2121/2121 [==============================] - 1s 575us/step - loss: 0.0051 - acc: 0.9991 - val_loss: 1.6721e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.00000\n",
      "Epoch 47/150\n",
      "2121/2121 [==============================] - 2s 921us/step - loss: 0.0118 - acc: 0.9953 - val_loss: 1.8325e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.00000\n",
      "Epoch 48/150\n",
      "2121/2121 [==============================] - 1s 678us/step - loss: 0.0097 - acc: 0.9976 - val_loss: 7.0704e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.00000\n",
      "Epoch 49/150\n",
      "2121/2121 [==============================] - 2s 810us/step - loss: 0.0060 - acc: 0.9986 - val_loss: 1.0183e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.00000\n",
      "Epoch 50/150\n",
      "2121/2121 [==============================] - 2s 899us/step - loss: 0.0034 - acc: 0.9991 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.00000\n",
      "Epoch 51/150\n",
      "2121/2121 [==============================] - 1s 545us/step - loss: 0.0063 - acc: 0.9981 - val_loss: 9.6279e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.00000\n",
      "Epoch 52/150\n",
      "2121/2121 [==============================] - 1s 589us/step - loss: 0.0074 - acc: 0.9962 - val_loss: 0.0121 - val_acc: 0.9973\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.00000\n",
      "Epoch 53/150\n",
      "2121/2121 [==============================] - 1s 553us/step - loss: 0.0113 - acc: 0.9958 - val_loss: 0.0155 - val_acc: 0.9973\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.00000\n",
      "Epoch 54/150\n",
      "2121/2121 [==============================] - 1s 567us/step - loss: 0.0049 - acc: 0.9981 - val_loss: 1.0956e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.00000\n",
      "Epoch 55/150\n",
      "2121/2121 [==============================] - 1s 479us/step - loss: 0.0086 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.00000\n",
      "Epoch 56/150\n",
      "2121/2121 [==============================] - 1s 670us/step - loss: 0.2145 - acc: 0.9774 - val_loss: 1.8449e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.00000\n",
      "Epoch 57/150\n",
      "2121/2121 [==============================] - 1s 575us/step - loss: 0.0363 - acc: 0.9943 - val_loss: 9.5882e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.00000\n",
      "Epoch 58/150\n",
      "2121/2121 [==============================] - 1s 663us/step - loss: 0.0222 - acc: 0.9939 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.00000\n",
      "Epoch 59/150\n",
      "2121/2121 [==============================] - 1s 656us/step - loss: 0.0214 - acc: 0.9934 - val_loss: 1.1953e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.00000\n",
      "Epoch 60/150\n",
      "2121/2121 [==============================] - 1s 582us/step - loss: 0.0082 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.00000\n",
      "Epoch 61/150\n",
      "2121/2121 [==============================] - 1s 508us/step - loss: 0.0096 - acc: 0.9962 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.00000\n",
      "Epoch 62/150\n",
      "2121/2121 [==============================] - 1s 553us/step - loss: 0.0064 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.00000\n",
      "Epoch 63/150\n",
      "2121/2121 [==============================] - 1s 555us/step - loss: 0.0060 - acc: 0.9986 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.00000\n",
      "Epoch 64/150\n",
      "2121/2121 [==============================] - 1s 590us/step - loss: 0.0129 - acc: 0.9948 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.00000\n",
      "Epoch 65/150\n",
      "2121/2121 [==============================] - 1s 648us/step - loss: 0.0053 - acc: 0.9986 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.00000\n",
      "Epoch 66/150\n",
      "2121/2121 [==============================] - 1s 556us/step - loss: 0.0068 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.00000\n",
      "Epoch 67/150\n",
      "2121/2121 [==============================] - 1s 575us/step - loss: 0.0049 - acc: 0.9986 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.00000\n",
      "Epoch 68/150\n",
      "2121/2121 [==============================] - 1s 560us/step - loss: 0.0040 - acc: 0.9991 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.00000\n",
      "Epoch 69/150\n",
      "2121/2121 [==============================] - 1s 545us/step - loss: 0.0035 - acc: 0.9991 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.00000\n",
      "Epoch 70/150\n",
      "2121/2121 [==============================] - 1s 538us/step - loss: 0.0067 - acc: 0.9976 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.00000\n",
      "Epoch 71/150\n",
      "2121/2121 [==============================] - 1s 597us/step - loss: 0.0033 - acc: 0.9986 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.00000\n",
      "Epoch 72/150\n",
      "2121/2121 [==============================] - 1s 538us/step - loss: 0.0050 - acc: 0.9976 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.00000\n",
      "Epoch 73/150\n",
      "2121/2121 [==============================] - 1s 501us/step - loss: 0.0044 - acc: 0.9986 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.00000\n",
      "Epoch 74/150\n",
      "2121/2121 [==============================] - 1s 486us/step - loss: 0.0019 - acc: 0.9995 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.00000\n",
      "Epoch 75/150\n",
      "2121/2121 [==============================] - 1s 494us/step - loss: 0.0110 - acc: 0.9953 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.00000\n",
      "Epoch 76/150\n",
      "2121/2121 [==============================] - 1s 486us/step - loss: 0.0054 - acc: 0.9981 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.00000\n",
      "Epoch 77/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2121/2121 [==============================] - 1s 486us/step - loss: 0.0110 - acc: 0.9953 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.00000\n",
      "Epoch 78/150\n",
      "2121/2121 [==============================] - 1s 486us/step - loss: 0.0060 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.00000\n",
      "Epoch 79/150\n",
      "2121/2121 [==============================] - 1s 538us/step - loss: 0.0040 - acc: 0.9991 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.00000\n",
      "Epoch 80/150\n",
      "2121/2121 [==============================] - 1s 685us/step - loss: 0.0074 - acc: 0.9967 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.00000\n",
      "Epoch 81/150\n",
      "2121/2121 [==============================] - 1s 583us/step - loss: 0.0056 - acc: 0.9981 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.00000\n",
      "Epoch 82/150\n",
      "2121/2121 [==============================] - 1s 589us/step - loss: 0.0045 - acc: 0.9981 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.00000\n",
      "Epoch 83/150\n",
      "2121/2121 [==============================] - 1s 545us/step - loss: 0.0042 - acc: 0.9981 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.00000\n",
      "Epoch 84/150\n",
      "2121/2121 [==============================] - 1s 678us/step - loss: 0.0071 - acc: 0.9962 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.00000\n",
      "Epoch 85/150\n",
      "2121/2121 [==============================] - 2s 760us/step - loss: 0.0032 - acc: 0.9991 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.00000\n",
      "Epoch 86/150\n",
      "2121/2121 [==============================] - 1s 538us/step - loss: 0.0053 - acc: 0.9981 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.00000\n",
      "Epoch 87/150\n",
      "2121/2121 [==============================] - 1s 553us/step - loss: 0.0040 - acc: 0.9986 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.00000\n",
      "Epoch 88/150\n",
      "2121/2121 [==============================] - 1s 604us/step - loss: 0.0034 - acc: 0.9986 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.00000\n",
      "Epoch 89/150\n",
      "2121/2121 [==============================] - 1s 516us/step - loss: 0.0039 - acc: 0.9986 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.00000\n",
      "Epoch 90/150\n",
      "2121/2121 [==============================] - 1s 530us/step - loss: 0.0080 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.00000\n",
      "Epoch 91/150\n",
      "2121/2121 [==============================] - 1s 538us/step - loss: 0.0072 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.00000\n",
      "Epoch 92/150\n",
      "2121/2121 [==============================] - 1s 553us/step - loss: 0.0073 - acc: 0.9976 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.00000\n",
      "Epoch 93/150\n",
      "2121/2121 [==============================] - 1s 560us/step - loss: 0.0031 - acc: 0.9986 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.00000\n",
      "Epoch 94/150\n",
      "2121/2121 [==============================] - 1s 523us/step - loss: 0.0058 - acc: 0.9967 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.00000\n",
      "Epoch 95/150\n",
      "2121/2121 [==============================] - 1s 560us/step - loss: 0.0039 - acc: 0.9991 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.00000\n",
      "Epoch 96/150\n",
      "2121/2121 [==============================] - 1s 523us/step - loss: 0.0038 - acc: 0.9981 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.00000\n",
      "Epoch 97/150\n",
      "2121/2121 [==============================] - 1s 523us/step - loss: 0.0036 - acc: 0.9986 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.00000\n",
      "Epoch 98/150\n",
      "2121/2121 [==============================] - 1s 604us/step - loss: 0.0082 - acc: 0.9976 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.00000\n",
      "Epoch 99/150\n",
      "2121/2121 [==============================] - 1s 619us/step - loss: 0.0070 - acc: 0.9967 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.00000\n",
      "Epoch 100/150\n",
      "2121/2121 [==============================] - 1s 604us/step - loss: 0.0047 - acc: 0.9986 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.00000\n",
      "Epoch 101/150\n",
      "2121/2121 [==============================] - 1s 523us/step - loss: 0.0074 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.00000\n",
      "Epoch 102/150\n",
      "2121/2121 [==============================] - 1s 545us/step - loss: 0.0016 - acc: 0.9991 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.00000\n",
      "Epoch 103/150\n",
      "2121/2121 [==============================] - 1s 575us/step - loss: 0.0053 - acc: 0.9976 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.00000\n",
      "Epoch 104/150\n",
      "2121/2121 [==============================] - 1s 523us/step - loss: 0.0056 - acc: 0.9976 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.00000\n",
      "Epoch 105/150\n",
      "2121/2121 [==============================] - 1s 523us/step - loss: 0.0033 - acc: 0.9981 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.00000\n",
      "Epoch 106/150\n",
      "2121/2121 [==============================] - 1s 538us/step - loss: 0.0072 - acc: 0.9962 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.00000\n",
      "Epoch 107/150\n",
      "2121/2121 [==============================] - 1s 523us/step - loss: 0.0059 - acc: 0.9981 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.00000\n",
      "Epoch 108/150\n",
      "2121/2121 [==============================] - 1s 560us/step - loss: 0.0079 - acc: 0.9948 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.00000\n",
      "Epoch 109/150\n",
      "2121/2121 [==============================] - 1s 560us/step - loss: 0.0130 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.00000\n",
      "Epoch 110/150\n",
      "2121/2121 [==============================] - 1s 553us/step - loss: 0.0357 - acc: 0.9943 - val_loss: 0.0388 - val_acc: 0.9973\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.00000\n",
      "Epoch 111/150\n",
      "2121/2121 [==============================] - 1s 516us/step - loss: 0.0314 - acc: 0.9958 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.00000\n",
      "Epoch 112/150\n",
      "2121/2121 [==============================] - 1s 634us/step - loss: 0.0126 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.00000\n",
      "Epoch 113/150\n",
      "2121/2121 [==============================] - 1s 508us/step - loss: 0.0115 - acc: 0.9981 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.00000\n",
      "Epoch 114/150\n",
      "2121/2121 [==============================] - 1s 567us/step - loss: 0.0117 - acc: 0.9981 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.00000\n",
      "Epoch 115/150\n",
      "2121/2121 [==============================] - 1s 516us/step - loss: 0.0106 - acc: 0.9981 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.00000\n",
      "Epoch 116/150\n",
      "2121/2121 [==============================] - 1s 597us/step - loss: 0.0119 - acc: 0.9976 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.00000\n",
      "Epoch 117/150\n",
      "2121/2121 [==============================] - 1s 567us/step - loss: 0.0127 - acc: 0.9991 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.00000\n",
      "Epoch 118/150\n",
      "2121/2121 [==============================] - 1s 530us/step - loss: 0.0132 - acc: 0.9962 - val_loss: 0.0332 - val_acc: 0.9947\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.00000\n",
      "Epoch 119/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2121/2121 [==============================] - 1s 523us/step - loss: 0.0150 - acc: 0.9962 - val_loss: 5.1446e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.00000\n",
      "Epoch 120/150\n",
      "2121/2121 [==============================] - 1s 553us/step - loss: 0.0104 - acc: 0.9986 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.00000\n",
      "Epoch 121/150\n",
      "2121/2121 [==============================] - 1s 560us/step - loss: 0.0142 - acc: 0.9967 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.00000\n",
      "Epoch 122/150\n",
      "2121/2121 [==============================] - 1s 634us/step - loss: 0.0164 - acc: 0.9962 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.00000\n",
      "Epoch 123/150\n",
      "2121/2121 [==============================] - 1s 641us/step - loss: 0.0124 - acc: 0.9981 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.00000\n",
      "Epoch 124/150\n",
      "2121/2121 [==============================] - 1s 641us/step - loss: 0.0114 - acc: 0.9976 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.00000\n",
      "Epoch 125/150\n",
      "2121/2121 [==============================] - 1s 626us/step - loss: 0.0105 - acc: 0.9981 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.00000\n",
      "Epoch 126/150\n",
      "2121/2121 [==============================] - 1s 589us/step - loss: 0.0130 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.00000\n",
      "Epoch 127/150\n",
      "2121/2121 [==============================] - 1s 545us/step - loss: 0.0077 - acc: 0.9986 - val_loss: 3.1965e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.00000\n",
      "Epoch 128/150\n",
      "2121/2121 [==============================] - 1s 575us/step - loss: 0.0526 - acc: 0.9925 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.00000\n",
      "Epoch 129/150\n",
      "2121/2121 [==============================] - 1s 560us/step - loss: 0.0046 - acc: 0.9976 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.00000\n",
      "Epoch 130/150\n",
      "2121/2121 [==============================] - 1s 656us/step - loss: 0.0035 - acc: 0.9986 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.00000\n",
      "Epoch 131/150\n",
      "2121/2121 [==============================] - 1s 611us/step - loss: 0.0044 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.00000\n",
      "Epoch 132/150\n",
      "2121/2121 [==============================] - 1s 604us/step - loss: 0.0198 - acc: 0.9958 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.00000\n",
      "Epoch 133/150\n",
      "2121/2121 [==============================] - 1s 567us/step - loss: 0.0221 - acc: 0.9967 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.00000\n",
      "Epoch 134/150\n",
      "2121/2121 [==============================] - 1s 516us/step - loss: 0.0200 - acc: 0.9967 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.00000\n",
      "Epoch 135/150\n",
      "2121/2121 [==============================] - 1s 582us/step - loss: 0.0188 - acc: 0.9976 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.00000\n",
      "Epoch 136/150\n",
      "2121/2121 [==============================] - 1s 669us/step - loss: 0.0203 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.00000\n",
      "Epoch 137/150\n",
      "2121/2121 [==============================] - 1s 663us/step - loss: 0.0181 - acc: 0.9981 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.00000\n",
      "Epoch 138/150\n",
      "2121/2121 [==============================] - 2s 1ms/step - loss: 0.0183 - acc: 0.9976 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.00000\n",
      "Epoch 139/150\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 0.0198 - acc: 0.996 - 1s 545us/step - loss: 0.0189 - acc: 0.9967 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.00000\n",
      "Epoch 140/150\n",
      "2121/2121 [==============================] - 2s 1ms/step - loss: 0.0223 - acc: 0.9953 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.00000\n",
      "Epoch 141/150\n",
      "2121/2121 [==============================] - 1s 681us/step - loss: 0.0121 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.00000\n",
      "Epoch 142/150\n",
      "2121/2121 [==============================] - 1s 516us/step - loss: 0.0110 - acc: 0.9981 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.00000\n",
      "Epoch 143/150\n",
      "2121/2121 [==============================] - 1s 501us/step - loss: 0.0126 - acc: 0.9967 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.00000\n",
      "Epoch 144/150\n",
      "2121/2121 [==============================] - 1s 538us/step - loss: 0.0163 - acc: 0.9967 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.00000\n",
      "Epoch 145/150\n",
      "2121/2121 [==============================] - 2s 1ms/step - loss: 0.0099 - acc: 0.9986 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.00000\n",
      "Epoch 146/150\n",
      "2121/2121 [==============================] - 2s 715us/step - loss: 0.0100 - acc: 0.9981 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.00000\n",
      "Epoch 147/150\n",
      "2121/2121 [==============================] - 1s 501us/step - loss: 0.0096 - acc: 0.9986 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.00000\n",
      "Epoch 148/150\n",
      "2121/2121 [==============================] - 1s 641us/step - loss: 0.0120 - acc: 0.9972 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.00000\n",
      "Epoch 149/150\n",
      "2121/2121 [==============================] - 1s 623us/step - loss: 0.0127 - acc: 0.9967 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.00000\n",
      "Epoch 150/150\n",
      "2121/2121 [==============================] - 1s 538us/step - loss: 0.0152 - acc: 0.9958 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.00000\n"
     ]
    }
   ],
   "source": [
    "input_shape = xTrain.shape\n",
    "print(input_shape)\n",
    "model = create_model(vocabSize, maxLengthz, input_shape)\n",
    "model.summary()\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "#model.summary()\n",
    "\n",
    "modelFileName = 'modelLSTM.h5'\n",
    "checkpoint = ModelCheckpoint(modelFileName, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "hist = model.fit(xTrain, yTrain, epochs = 150, batch_size = 32, validation_data = (xValid, yValid), callbacks = [checkpoint])\n",
    "\n",
    "model.save(modelFileName)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('modelLSTM.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    cleanedSentence = re.sub(r'[^ a-z A-Z 0-9]', \" \", text)\n",
    "    testWord = word_tokenize(cleanedSentence)\n",
    "    testWord = [w.lower() for w in testWord]\n",
    "    testTokens = wordTokens.texts_to_sequences(testWord)\n",
    "    \n",
    "    print(testWord)\n",
    "    if [] in testTokens: #Check for unknown words\n",
    "        testTokens = list(filter(None, testTokens))\n",
    "    \n",
    "    testTokens = np.array(testTokens).reshape(1, len(testTokens))\n",
    "    x = padder(testTokens, maxLengthz)\n",
    "    pred = model.predict_proba(x)\n",
    "  \n",
    "    return pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIntent(predicts, intents):\n",
    "    prediction = predicts[0]\n",
    " \n",
    "    intents = np.array(intents)\n",
    "    ids = np.argsort(-prediction)\n",
    "    intents = intents[ids]\n",
    "    predictions = -np.sort(-prediction)\n",
    " \n",
    "    for i in range(predicts.shape[1]):\n",
    "        print(\"%s has confidence = %s\" % (intents[i], (predictions[i])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wire', 'is', 'vessel']\n",
      "create_inheritance has confidence = 1.0\n",
      "add_attribute has confidence = 0.0\n",
      "create_composition has confidence = 0.0\n",
      "create_association has confidence = 0.0\n",
      "add_class has confidence = 0.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "text = \"wire is vessel\"\n",
    "pred = predict(text)\n",
    "print(getIntent(pred, keyIntent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
